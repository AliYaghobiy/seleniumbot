#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import json
import time
import logging
import random
import platform
import subprocess
import re
import threading
import queue
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List, Dict, Optional
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.action_chains import ActionChains
from selenium.common.exceptions import TimeoutException, NoSuchElementException
from urllib.parse import urljoin
import sys
import os

class ProductScraper:
    """
    Ø±Ø¨Ø§Øª Ø§Ø³Ú©Ø±Ù¾ÛŒÙ†Ú¯ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø³Ù„Ù†ÛŒÙˆÙ… - Ù†Ø³Ø®Ù‡ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ´Ø¯Ù‡
    """
    
    def __init__(self, config_path: str = "config.json"):
        """
        Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø±Ø¨Ø§Øª Ø¨Ø§ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú©Ø§Ù†ÙÛŒÚ¯
        """
        self.config = self.load_config(config_path)
        self.driver = None
        self.scraped_products = []
        self.tab_handles = []  # Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ù†Ú¯Ù‡Ø¯Ø§Ø±ÛŒ handle Ù‡Ø§ÛŒ ØªØ¨â€ŒÙ‡Ø§ 
        self.setup_logging()
        
    def setup_logging(self):
        """
        ØªÙ†Ø¸ÛŒÙ… Ø³ÛŒØ³ØªÙ… Ù„Ø§Ú¯
        """
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('scraper.log', encoding='utf-8'),
                logging.StreamHandler(sys.stdout)
            ]
        )
        self.logger = logging.getLogger(__name__)
        
    def load_config(self, config_path: str) -> Dict:
        """
        Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„ Ú©Ø§Ù†ÙÛŒÚ¯
        """
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
            print(f"âœ… ÙØ§ÛŒÙ„ Ú©Ø§Ù†ÙÛŒÚ¯ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯: {config_path}")
            return config
        except FileNotFoundError:
            print(f"âŒ ÙØ§ÛŒÙ„ Ú©Ø§Ù†ÙÛŒÚ¯ ÛŒØ§ÙØª Ù†Ø´Ø¯: {config_path}")
            return {}
        except json.JSONDecodeError as e:
            print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± ÙØ±Ù…Øª JSON ÙØ§ÛŒÙ„ Ú©Ø§Ù†ÙÛŒÚ¯: {e}")
            sys.exit(1)
            
    def detect_chrome_binary(self):
        """
        ØªØ´Ø®ÛŒØµ Ù…Ø³ÛŒØ± Chrome Ø¯Ø± Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù
        """
        chrome_paths = [
            '/usr/bin/google-chrome',
            '/usr/bin/google-chrome-stable', 
            '/usr/bin/chromium-browser',
            '/usr/bin/chromium',
            '/snap/bin/chromium',
            '/Applications/Google Chrome.app/Contents/MacOS/Google Chrome',
            'C:\\Program Files\\Google\\Chrome\\Application\\chrome.exe',
            'C:\\Program Files (x86)\\Google\\Chrome\\Application\\chrome.exe'
        ]
        
        for path in chrome_paths:
            if os.path.exists(path):
                self.logger.info(f"âœ… Chrome ÛŒØ§ÙØª Ø´Ø¯ Ø¯Ø±: {path}")
                return path
                
        try:
            result = subprocess.run(['which', 'google-chrome'], capture_output=True, text=True)
            if result.returncode == 0:
                path = result.stdout.strip()
                self.logger.info(f"âœ… Chrome ÛŒØ§ÙØª Ø´Ø¯ Ø¨Ø§ which: {path}")
                return path
        except:
            pass
            
        try:
            result = subprocess.run(['which', 'chromium-browser'], capture_output=True, text=True)
            if result.returncode == 0:
                path = result.stdout.strip()
                self.logger.info(f"âœ… Chromium ÛŒØ§ÙØª Ø´Ø¯ Ø¨Ø§ which: {path}")
                return path
        except:
            pass
            
        return None

    def install_chrome_ubuntu(self):
        """
        Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ù†ØµØ¨ Chrome Ø¯Ø± Ubuntu/Debian
        """
        print("ğŸ“‹ Ø¨Ø±Ø§ÛŒ Ù†ØµØ¨ Google Chrome Ø¯Ø± Ubuntu/Debian:")
        print("wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | sudo apt-key add -")
        print("echo 'deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main' | sudo tee /etc/apt/sources.list.d/google-chrome.list")
        print("sudo apt-get update")
        print("sudo apt-get install google-chrome-stable")
        print("\nğŸ“‹ ÛŒØ§ Ø¨Ø±Ø§ÛŒ Ù†ØµØ¨ Chromium:")
        print("sudo apt-get install chromium-browser")

    def human_like_delay(self, min_seconds=0.5, max_seconds=1.5):
        """
        ØªØ§Ø®ÛŒØ± ØªØµØ§Ø¯ÙÛŒ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø³Ø±Ø¹Øª Ø¨ÛŒØ´ØªØ±
        """
        delay = random.uniform(min_seconds, max_seconds)
        time.sleep(delay)
        
    def human_like_scroll(self, pause_time=None):
        """
        Ø§Ø³Ú©Ø±ÙˆÙ„ Ø·Ø¨ÛŒØ¹ÛŒ Ù…Ø§Ù†Ù†Ø¯ Ø§Ù†Ø³Ø§Ù† Ø¨Ø±Ø§ÛŒ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² Ù„ÙˆØ¯ Ú©Ø§Ù…Ù„ Ù…Ø­ØµÙˆÙ„Ø§Øª
        """
        if pause_time is None:
            pause_time = random.uniform(0.5, 1.5)
            
        current_scroll = self.driver.execute_script("return window.pageYOffset;")
        total_height = self.driver.execute_script("return document.body.scrollHeight;")
        
        scroll_steps = random.randint(3, 6)
        step_height = (total_height - current_scroll) / scroll_steps
        
        for i in range(scroll_steps):
            scroll_to = current_scroll + (step_height * (i + 1))
            self.driver.execute_script(f"window.scrollTo(0, {scroll_to});")
            WebDriverWait(self.driver, 5).until(
                lambda d: d.execute_script("return document.readyState") == "complete"
            )
            time.sleep(random.uniform(0.3, 0.8))
            
        time.sleep(pause_time)
        
    def simulate_quick_mouse_movement(self, element):
        """
        Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ø³Ø±ÛŒØ¹ Ø­Ø±Ú©Øª Ù…ÙˆØ³
        """
        try:
            actions = ActionChains(self.driver)
            actions.move_to_element(element)
            actions.pause(random.uniform(0.1, 0.2))
            actions.perform()
        except Exception as e:
            self.logger.warning(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ø­Ø±Ú©Øª Ù…ÙˆØ³: {e}")
            
    def load_random_user_agents(self, file_path: str = "random.txt") -> List[str]:
        """
        Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ User-Agent Ù‡Ø§ÛŒ ØªØµØ§Ø¯ÙÛŒ Ø§Ø² ÙØ§ÛŒÙ„
        """
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                user_agents = [line.strip() for line in f.readlines() if line.strip()]
            if user_agents:
                self.logger.info(f"âœ… {len(user_agents)} User-Agent Ø§Ø² ÙØ§ÛŒÙ„ {file_path} Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯")
                return user_agents
            else:
                self.logger.warning(f"âš ï¸ ÙØ§ÛŒÙ„ {file_path} Ø®Ø§Ù„ÛŒ Ø§Ø³Øª")
                return []
        except FileNotFoundError:
            self.logger.warning(f"âš ï¸ ÙØ§ÛŒÙ„ {file_path} ÛŒØ§ÙØª Ù†Ø´Ø¯")
            return []
        except Exception as e:
            self.logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ User-Agent Ù‡Ø§: {e}")
            return []

    def get_random_user_agent(self) -> str:
        """
        Ø§Ù†ØªØ®Ø§Ø¨ ØªØµØ§Ø¯ÙÛŒ User-Agent
        """
        user_agents = self.load_random_user_agents()
        if user_agents:
            selected_ua = random.choice(user_agents)
            self.logger.info(f"ğŸ² User-Agent ØªØµØ§Ø¯ÙÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯: {selected_ua[:50]}...")
            return selected_ua
        default_ua = 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/136.0.0.0 Safari/537.36'
        self.logger.info(f"ğŸ”„ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² User-Agent Ù¾ÛŒØ´â€ŒÙØ±Ø¶")
        return default_ua

    def setup_driver(self):
        """
        Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ù…Ø±ÙˆØ±Ú¯Ø± Ø¨Ø§ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¨Ù‡ÛŒÙ†Ù‡
        """
        try:
            chrome_options = Options()
            system_name = platform.system().lower()
            self.logger.info(f"ğŸ–¥ï¸ Ø³ÛŒØ³ØªÙ…â€ŒØ¹Ø§Ù…Ù„ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯Ù‡: {system_name}")
            
            chrome_binary = self.detect_chrome_binary()
            if chrome_binary:
                chrome_options.binary_location = chrome_binary
            else:
                self.logger.error("âŒ Google Chrome ÛŒØ§ Chromium ÛŒØ§ÙØª Ù†Ø´Ø¯!")
                self.install_chrome_ubuntu()
                sys.exit(1)
            
            chrome_options.add_argument('--disable-gpu')
            chrome_options.add_argument('--no-sandbox')
            chrome_options.add_argument('--disable-dev-shm-usage')
            chrome_options.add_argument('--disable-images')
            chrome_options.add_argument('--disable-css-background-images')
            chrome_options.add_argument('--disable-extensions')
            chrome_options.add_argument('--disable-plugins')
            chrome_options.add_argument('--disable-blink-features=AutomationControlled')
            chrome_options.add_argument('--max_old_space_size=4096')
            chrome_options.add_argument('--disable-background-timer-throttling')
            chrome_options.add_argument('--disable-renderer-backgrounding')

            
            random_user_agent = self.get_random_user_agent()
            chrome_options.add_argument(f'--user-agent={random_user_agent}')
            
            chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
            chrome_options.add_experimental_option('useAutomationExtension', False)
            
            chromedriver_path = '/usr/bin/chromedriver'
            if os.path.exists(chromedriver_path):
                self.logger.info(f"âœ… Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² chromedriver Ø³ÛŒØ³ØªÙ…: {chromedriver_path}")
                service = Service(chromedriver_path, port=9515)
            else:
                self.logger.error("âŒ chromedriver ÛŒØ§ÙØª Ù†Ø´Ø¯")
                sys.exit(1)
            
            self.driver = webdriver.Chrome(service=service, options=chrome_options)
            self.driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
            self.driver.implicitly_wait(5)
            self.driver.maximize_window()
            self.logger.info("âœ… Ù…Ø±ÙˆØ±Ú¯Ø± Ú©Ø±ÙˆÙ… Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø´Ø¯")
            
        except Exception as e:
            self.logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ù…Ø±ÙˆØ±Ú¯Ø±: {e}")
            sys.exit(1)
   
    def scroll_page(self, scroll_count: int):
        """
        Ø§Ø³Ú©Ø±ÙˆÙ„ Ø·Ø¨ÛŒØ¹ÛŒ ØµÙØ­Ù‡ Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¨ÛŒØ´ØªØ±
        """
        self.logger.info(f"ğŸ”„ Ø´Ø±ÙˆØ¹ Ø§Ø³Ú©Ø±ÙˆÙ„ Ø·Ø¨ÛŒØ¹ÛŒ ØµÙØ­Ù‡ - ØªØ¹Ø¯Ø§Ø¯: {scroll_count}")
        
        for i in range(scroll_count):
            self.logger.info(f"ğŸ“œ Ø§Ø³Ú©Ø±ÙˆÙ„ {i+1} Ø§Ø² {scroll_count}")
            self.human_like_scroll()
            self.human_like_delay(1.5, 3.5)
            if random.random() < 0.3:
                self.driver.execute_script("window.scrollBy(0, -100);")
                time.sleep(random.uniform(0.5, 1.0))
        
        self.driver.execute_script("window.scrollTo({top: 0, behavior: 'smooth'});")
        self.human_like_delay(2, 3)
        
    def extract_product_links(self) -> List[str]:
        """
        Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¨Ø§ Ø§Ù†ØªØ¸Ø§Ø± Ù„ÙˆØ¯ Ú©Ø§Ù…Ù„
        """
        self.logger.info("ğŸ” Ø´Ø±ÙˆØ¹ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª...")
        
        try:
            self.driver.get(self.config['main_page_url'])
            WebDriverWait(self.driver, 10).until(
                lambda d: d.execute_script("return document.readyState") == "complete"
            )
            self.human_like_delay(2, 3)
            
            scroll_count = self.config.get('scroll_count', 0)
            if scroll_count > 0:
                self.scroll_page(scroll_count)
            
            WebDriverWait(self.driver, 10).until(
                EC.presence_of_all_elements_located((By.CSS_SELECTOR, self.config['selectors']['product_links']))
            )
            
            product_selector = self.config['selectors']['product_links']
            product_elements = self.driver.find_elements(By.CSS_SELECTOR, product_selector)
            
            product_links = []
            for element in product_elements:
                try:
                    href = element.get_attribute('href')
                    if href:
                        full_url = urljoin(self.config['main_page_url'], href)
                        if full_url not in product_links:
                            product_links.append(full_url)
                except Exception:
                    continue
                
            self.logger.info(f"âœ… ØªØ¹Ø¯Ø§Ø¯ {len(product_links)} Ù„ÛŒÙ†Ú© Ù…Ø­ØµÙˆÙ„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯")
            return product_links
            
        except Exception as e:
            self.logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª: {e}")
            return []

    def detect_brand_from_category(self, category_text: str) -> Optional[str]:
        """
        ØªØ´Ø®ÛŒØµ Ø¨Ø±Ù†Ø¯ Ø§Ø² Ù…ØªÙ† Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ
        """
        pattern = r'(.+?)\s*\((.+?)\)'
        match = re.match(pattern, category_text.strip())
        if match:
            brand_persian = match.group(1).strip()
            brand_english = match.group(2).strip()
            self.logger.info(f"ğŸ·ï¸ Ø¨Ø±Ù†Ø¯ ØªØ´Ø®ÛŒØµ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯: {brand_persian} ({brand_english})")
            return f"{brand_persian} ({brand_english})"
        return None

    def extract_specifications(self, product_url: str) -> Dict:
        """
        Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø´Ø®ØµØ§Øª Ú©Ù„ÛŒØ¯ÛŒ Ùˆ Ú©Ù„ÛŒ Ù…Ø­ØµÙˆÙ„
        """
        specifications = {
            'key_specs': [],
            'general_specs': []
        }
        
        try:
            key_specs_selector = self.config['selectors']['specifications']['key_specs_section']
            general_specs_selector = self.config['selectors']['specifications']['general_specs_section']
            spec_items_selector = self.config['selectors']['specifications']['spec_items']
            spec_title_selector = self.config['selectors']['specifications']['spec_title']
            spec_value_selector = self.config['selectors']['specifications']['spec_value']
            
            try:
                spec_elements = WebDriverWait(self.driver, 5).until(
                    EC.presence_of_all_elements_located((By.CSS_SELECTOR, spec_items_selector))
                )
                for element in spec_elements:
                    try:
                        title = element.find_element(By.CSS_SELECTOR, spec_title_selector).text.strip()
                        value = element.find_element(By.CSS_SELECTOR, spec_value_selector).text.strip()
                        if title and value:
                            if key_specs_selector in element.get_attribute('class') or 'key' in element.get_attribute('class').lower():
                                specifications['key_specs'].append({
                                    'title': title,
                                    'body': value
                                })
                            else:
                                specifications['general_specs'].append({
                                    'title': title,
                                    'body': value
                                })
                    except Exception:
                        continue
            except TimeoutException:
                self.logger.warning("âš ï¸ Ù‡ÛŒÚ† Ù…Ø´Ø®ØµÙ‡â€ŒØ§ÛŒ Ø¨Ø§ Ø³Ù„Ú©ØªÙˆØ±Ù‡Ø§ÛŒ Ø§ØµÙ„ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯")
                self.extract_specs_alternative_method(specifications)
                
        except Exception as e:
            self.logger.warning(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø´Ø®ØµØ§Øª: {e}")
        
        return specifications

    def extract_specs_alternative_method(self, specifications: Dict):
        """
        Ø±ÙˆØ´ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø´Ø®ØµØ§Øª
        """
        try:
            all_elements = self.driver.find_elements(By.XPATH, "//*[contains(text(), 'Ù…Ø´Ø®ØµØ§Øª')]")
            for element in all_elements:
                try:
                    parent = element.find_element(By.XPATH, './..')
                    spec_items = parent.find_elements(By.XPATH, './/*')
                    for item in spec_items:
                        try:
                            text = item.text.strip()
                            if text and '\n' in text:
                                lines = text.split('\n')
                                if len(lines) >= 2:
                                    title = lines[0].strip()
                                    body = lines[1].strip()
                                    if title and body and len(title) < 100 and len(body) < 200:
                                        if any(keyword in title.lower() for keyword in ['Ø­Ø§ÙØ¸Ù‡', 'Ø¨Ø§ØªØ±ÛŒ', 'Ø¯ÙˆØ±Ø¨ÛŒÙ†', 'Ø³ÛŒÙ…']):
                                            specifications['key_specs'].append({
                                                'title': title,
                                                'body': body
                                            })
                                        else:
                                            specifications['general_specs'].append({
                                                'title': title,
                                                'body': body
                                            })
                        except Exception:
                            continue
                except Exception:
                    continue
        except Exception as e:
            self.logger.warning(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø±ÙˆØ´ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø´Ø®ØµØ§Øª: {e}")
            
    def extract_product_data(self, product_url: str) -> Optional[Dict]:
        """
        Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ´Ø¯Ù‡ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø­ØµÙˆÙ„
        """
        try:
            self.logger.info(f"ğŸ“Š Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø­ØµÙˆÙ„: {product_url}")
            self.driver.get(product_url)
            self.human_like_delay(1.5, 2.5)
            self.driver.execute_script("window.scrollTo(0, 500);")
            self.human_like_delay(0.5, 1)
            
            product_data = {
                'url': product_url,
                'title': None,
                'categories': [],
                'brand': None,
                'specifications': {
                    'key_specs': [],
                    'general_specs': []
                }
            }
            
            try:
                title_element = WebDriverWait(self.driver, 6).until(
                    EC.presence_of_element_located((By.CSS_SELECTOR, self.config['selectors']['product_title']))
                )
                product_data['title'] = title_element.text.strip()
                self.logger.info(f"ğŸ“ Ø¹Ù†ÙˆØ§Ù† Ù…Ø­ØµÙˆÙ„: {product_data['title']}")
            except TimeoutException:
                self.logger.warning(f"âš ï¸ Ø¹Ù†ÙˆØ§Ù† Ù…Ø­ØµÙˆÙ„ ÛŒØ§ÙØª Ù†Ø´Ø¯: {product_url}")
                
            categories_selectors = self.config['selectors']['categories']
            categories_found = []
            for i, selector in enumerate(categories_selectors):
                try:
                    category_element = self.driver.find_element(By.CSS_SELECTOR, selector)
                    category_text = category_element.text.strip()
                    if category_text:
                        categories_found.append({
                            'level': i + 1,
                            'name': category_text
                        })
                        self.logger.info(f"ğŸ·ï¸ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ {i+1}: {category_text}")
                except NoSuchElementException:
                    break
                except Exception as e:
                    self.logger.warning(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ {i+1}: {e}")
            
            if categories_found:
                last_category = categories_found[-1]
                brand = self.detect_brand_from_category(last_category['name'])
                if brand:
                    product_data['brand'] = brand
                    product_data['categories'] = categories_found[:-1]
                    self.logger.info(f"ğŸ·ï¸ Ø¨Ø±Ù†Ø¯ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯: {brand}")
                else:
                    product_data['categories'] = categories_found
            
            self.logger.info("ğŸ” Ø´Ø±ÙˆØ¹ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø´Ø®ØµØ§Øª...")
            specifications = self.extract_specifications(product_url)
            product_data['specifications'] = specifications
            self.logger.info(f"âœ… ØªØ¹Ø¯Ø§Ø¯ Ù…Ø´Ø®ØµØ§Øª Ú©Ù„ÛŒØ¯ÛŒ: {len(specifications['key_specs'])}")
            self.logger.info(f"âœ… ØªØ¹Ø¯Ø§Ø¯ Ù…Ø´Ø®ØµØ§Øª Ú©Ù„ÛŒ: {len(specifications['general_specs'])}")
            
            self.human_like_delay(0.3, 0.8)
            return product_data
            
        except Exception as e:
            self.logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø­ØµÙˆÙ„ {product_url}: {e}")
            return None
            
    def save_data(self):
        """
        Ø°Ø®ÛŒØ±Ù‡ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯Ù‡
        """
        output_config = self.config.get('output', {})
        filename = output_config.get('filename', 'scraped_products.json')
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(self.scraped_products, f, ensure_ascii=False, indent=2)
                
            self.logger.info(f"ğŸ’¾ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¯Ø± ÙØ§ÛŒÙ„ {filename} Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯")
            
            total_products = len(self.scraped_products)
            successful_products = len([p for p in self.scraped_products if p.get('title')])
            products_with_brand = len([p for p in self.scraped_products if p.get('brand')])
            products_with_key_specs = len([p for p in self.scraped_products if p.get('specifications', {}).get('key_specs')])
            products_with_general_specs = len([p for p in self.scraped_products if p.get('specifications', {}).get('general_specs')])
            
            print(f"\nğŸ“ˆ Ø¢Ù…Ø§Ø± Ù†Ù‡Ø§ÛŒÛŒ:")
            print(f"ğŸ”¢ ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ù…Ø­ØµÙˆÙ„Ø§Øª: {total_products}")
            print(f"âœ… Ù…Ø­ØµÙˆÙ„Ø§Øª Ù…ÙˆÙÙ‚: {successful_products}")
            print(f"ğŸ·ï¸ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¨Ø§ Ø¨Ø±Ù†Ø¯: {products_with_brand}")
            print(f"ğŸ”§ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¨Ø§ Ù…Ø´Ø®ØµØ§Øª Ú©Ù„ÛŒØ¯ÛŒ: {products_with_key_specs}")
            print(f"ğŸ“‹ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¨Ø§ Ù…Ø´Ø®ØµØ§Øª Ú©Ù„ÛŒ: {products_with_general_specs}")
            print(f"âŒ Ù…Ø­ØµÙˆÙ„Ø§Øª Ù†Ø§Ù…ÙˆÙÙ‚: {total_products - successful_products}")
            
        except Exception as e:
            self.logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ Ø§Ø·Ù„Ø§Ø¹Ø§Øª: {e}")
            
    def run(self):
        """
        Ø§Ø¬Ø±Ø§ÛŒ Ø§ØµÙ„ÛŒ Ø±Ø¨Ø§Øª
        """
        try:
            print("ğŸš€ Ø´Ø±ÙˆØ¹ Ø§Ø¬Ø±Ø§ÛŒ Ø±Ø¨Ø§Øª Ø§Ø³Ú©Ø±Ù¾ÛŒÙ†Ú¯ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ´Ø¯Ù‡...")
            self.setup_driver()
            product_links = self.extract_product_links()
            
            if not product_links:
                self.logger.error("âŒ Ù‡ÛŒÚ† Ù„ÛŒÙ†Ú© Ù…Ø­ØµÙˆÙ„ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯")
                return
                
            total_products = len(product_links)
            for i, product_url in enumerate(product_links, 1):
                print(f"\nğŸ”„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…Ø­ØµÙˆÙ„ {i} Ø§Ø² {total_products}")
                product_data = self.extract_product_data(product_url)
                if product_data:
                    self.scraped_products.append(product_data)
                if i < total_products:
                    delay = random.uniform(1, 3)
                    self.logger.info(f"â±ï¸ Ø§Ù†ØªØ¸Ø§Ø± {delay:.1f} Ø«Ø§Ù†ÛŒÙ‡ Ù‚Ø¨Ù„ Ø§Ø² Ù…Ø­ØµÙˆÙ„ Ø¨Ø¹Ø¯ÛŒ...")
                    time.sleep(delay)
                    
            self.save_data()
            print("\nğŸ‰ Ø±Ø¨Ø§Øª Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ú©Ø§Ø± Ø®ÙˆØ¯ Ø±Ø§ ØªÙ…Ø§Ù… Ú©Ø±Ø¯!")
            
        except KeyboardInterrupt:
            self.logger.info("â¹ï¸ Ø±Ø¨Ø§Øª ØªÙˆØ³Ø· Ú©Ø§Ø±Ø¨Ø± Ù…ØªÙˆÙ‚Ù Ø´Ø¯")
        except Exception as e:
            self.logger.error(f"âŒ Ø®Ø·Ø§ÛŒ Ú©Ù„ÛŒ Ø¯Ø± Ø§Ø¬Ø±Ø§ÛŒ Ø±Ø¨Ø§Øª: {e}")
        finally:
            self.cleanup()
            
    def cleanup(self):
        """
        ØªÙ…ÛŒØ² Ú©Ø±Ø¯Ù† Ù…Ù†Ø§Ø¨Ø¹
        """
        if self.driver:
            self.driver.quit()
            self.logger.info("ğŸ”’ Ù…Ø±ÙˆØ±Ú¯Ø± Ø¨Ø³ØªÙ‡ Ø´Ø¯")

    def setup_multiple_tabs(self, num_tabs: int = 2):
        """
        Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ú†Ù†Ø¯ÛŒÙ† ØªØ¨ Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ÙˆØ§Ø²ÛŒ
        """
        try:
            self.logger.info(f"ğŸ”„ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ {num_tabs} ØªØ¨ Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ÙˆØ§Ø²ÛŒ...")
            
            # Ø¨Ø§Ø² Ú©Ø±Ø¯Ù† ØªØ¨â€ŒÙ‡Ø§ÛŒ Ø§Ø¶Ø§ÙÛŒ
            for i in range(num_tabs - 1):
                self.driver.execute_script("window.open('about:blank', '_blank');")
                self.human_like_delay(0.3, 0.5)
            
            # Ø¯Ø±ÛŒØ§ÙØª handle Ù‡Ø§ÛŒ ØªÙ…Ø§Ù… ØªØ¨â€ŒÙ‡Ø§
            self.tab_handles = self.driver.window_handles
            self.logger.info(f"âœ… {len(self.tab_handles)} ØªØ¨ Ø¢Ù…Ø§Ø¯Ù‡ Ø´Ø¯")
            
            return self.tab_handles
            
        except Exception as e:
            self.logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ú†Ù†Ø¯ÛŒÙ† ØªØ¨: {e}")
            return [self.driver.current_window_handle]

    def extract_product_data_in_tab(self, product_url: str, tab_handle: str) -> Optional[Dict]:
        """
        Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø­ØµÙˆÙ„ Ø¯Ø± ØªØ¨ Ù…Ø´Ø®Øµ
        """
        try:
            # ØªØºÛŒÛŒØ± Ø¨Ù‡ ØªØ¨ Ù…Ø´Ø®Øµ
            self.driver.switch_to.window(tab_handle)
            
            self.logger.info(f"ğŸ“Š Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø­ØµÙˆÙ„ Ø¯Ø± ØªØ¨: {product_url}")
            self.driver.get(product_url)
            self.human_like_delay(1.5, 2.5)
            self.driver.execute_script("window.scrollTo(0, 500);")
            self.human_like_delay(0.5, 1)
            
            product_data = {
                'url': product_url,
                'title': None,
                'categories': [],
                'brand': None,
                'specifications': {
                    'key_specs': [],
                    'general_specs': []
                }
            }
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¹Ù†ÙˆØ§Ù† Ù…Ø­ØµÙˆÙ„
            try:
                title_element = WebDriverWait(self.driver, 6).until(
                    EC.presence_of_element_located((By.CSS_SELECTOR, self.config['selectors']['product_title']))
                )
                product_data['title'] = title_element.text.strip()
                self.logger.info(f"ğŸ“ Ø¹Ù†ÙˆØ§Ù† Ù…Ø­ØµÙˆÙ„: {product_data['title']}")
            except TimeoutException:
                self.logger.warning(f"âš ï¸ Ø¹Ù†ÙˆØ§Ù† Ù…Ø­ØµÙˆÙ„ ÛŒØ§ÙØª Ù†Ø´Ø¯: {product_url}")
                
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§
            categories_selectors = self.config['selectors']['categories']
            categories_found = []
            for i, selector in enumerate(categories_selectors):
                try:
                    category_element = self.driver.find_element(By.CSS_SELECTOR, selector)
                    category_text = category_element.text.strip()
                    if category_text:
                        categories_found.append({
                            'level': i + 1,
                            'name': category_text
                        })
                        self.logger.info(f"ğŸ·ï¸ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ {i+1}: {category_text}")
                except NoSuchElementException:
                    break
                except Exception as e:
                    self.logger.warning(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ {i+1}: {e}")
            
            # ØªØ´Ø®ÛŒØµ Ø¨Ø±Ù†Ø¯ Ø§Ø² Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ
            if categories_found:
                last_category = categories_found[-1]
                brand = self.detect_brand_from_category(last_category['name'])
                if brand:
                    product_data['brand'] = brand
                    product_data['categories'] = categories_found[:-1]
                    self.logger.info(f"ğŸ·ï¸ Ø¨Ø±Ù†Ø¯ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯: {brand}")
                else:
                    product_data['categories'] = categories_found
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø´Ø®ØµØ§Øª
            self.logger.info("ğŸ” Ø´Ø±ÙˆØ¹ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø´Ø®ØµØ§Øª...")
            specifications = self.extract_specifications(product_url)
            product_data['specifications'] = specifications
            self.logger.info(f"âœ… ØªØ¹Ø¯Ø§Ø¯ Ù…Ø´Ø®ØµØ§Øª Ú©Ù„ÛŒØ¯ÛŒ: {len(specifications['key_specs'])}")
            self.logger.info(f"âœ… ØªØ¹Ø¯Ø§Ø¯ Ù…Ø´Ø®ØµØ§Øª Ú©Ù„ÛŒ: {len(specifications['general_specs'])}")
            
            self.human_like_delay(0.3, 0.8)
            return product_data
            
        except Exception as e:
            self.logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø­ØµÙˆÙ„ {product_url}: {e}")
            return None

    def process_single_product_thread(self, product_url: str, tab_handle: str, thread_id: int, results_queue: queue.Queue):
        """
        Ù¾Ø±Ø¯Ø§Ø²Ø´ ÛŒÚ© Ù…Ø­ØµÙˆÙ„ Ø¯Ø± thread Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡
        """
        try:
            # ØªØ§Ø®ÛŒØ± Ú©ÙˆÚ†Ú© Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² ØªØ¯Ø§Ø®Ù„ Ùˆ Ú©Ø§Ù‡Ø´ ÙØ´Ø§Ø± connection pool
            time.sleep(thread_id * 0.5)
            
            # ØªØºÛŒÛŒØ± Ø¨Ù‡ ØªØ¨ Ù…Ø´Ø®Øµ
            self.driver.switch_to.window(tab_handle)
            
            self.logger.info(f"ğŸ“Š Thread {thread_id}: Ø´Ø±ÙˆØ¹ Ø§Ø³ØªØ®Ø±Ø§Ø¬ {product_url}")
            product_data = self.extract_product_data_in_tab(product_url, tab_handle)
            
            # Ù‚Ø±Ø§Ø± Ø¯Ø§Ø¯Ù† Ù†ØªÛŒØ¬Ù‡ Ø¯Ø± ØµÙ
            results_queue.put({
                'thread_id': thread_id,
                'product_data': product_data,
                'success': product_data is not None
            })
            
            self.logger.info(f"âœ… Thread {thread_id}: ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯")
            
        except Exception as e:
            self.logger.error(f"âŒ Thread {thread_id} Ø®Ø·Ø§: {e}")
            results_queue.put({
                'thread_id': thread_id,
                'product_data': None,
                'success': False
            })

    def process_products_parallel(self, product_links: List[str], num_tabs: int = 2):
        """
        Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙˆØ§Ù‚Ø¹Ø§Ù‹ Ù…ÙˆØ§Ø²ÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² threading
        """
        try:
            # Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ ØªØ¨â€ŒÙ‡Ø§ÛŒ Ù…ØªØ¹Ø¯Ø¯
            tab_handles = self.setup_multiple_tabs(num_tabs)
            total_products = len(product_links)
            processed_count = 0
            
            self.logger.info(f"ğŸš€ Ø´Ø±ÙˆØ¹ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù‡Ù…Ø²Ù…Ø§Ù† {total_products} Ù…Ø­ØµÙˆÙ„ Ø¨Ø§ {len(tab_handles)} ØªØ¨")
            
            # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¨Ù‡ ØµÙˆØ±Øª batch Ù‡Ø§ÛŒ Û³ ØªØ§ÛŒÛŒ Ù‡Ù…Ø²Ù…Ø§Ù†
            for batch_start in range(0, total_products, num_tabs):
                batch_end = min(batch_start + num_tabs, total_products)
                current_batch = product_links[batch_start:batch_end]
                
                print(f"\nğŸ“¦ Ø´Ø±ÙˆØ¹ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù‡Ù…Ø²Ù…Ø§Ù† batch {batch_start//num_tabs + 1}: Ù…Ø­ØµÙˆÙ„Ø§Øª {batch_start + 1} ØªØ§ {batch_end}")
                
                # Ø§ÛŒØ¬Ø§Ø¯ ØµÙ Ø¨Ø±Ø§ÛŒ Ù†ØªØ§ÛŒØ¬
                results_queue = queue.Queue()
                threads = []
                
                # Ø´Ø±ÙˆØ¹ thread Ù‡Ø§ Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù‡Ù…Ø²Ù…Ø§Ù†
                for i, product_url in enumerate(current_batch):
                    if i < len(tab_handles):
                        tab_handle = tab_handles[i]
                        processed_count += 1
                        
                        print(f"ğŸ”„ Ø´Ø±ÙˆØ¹ Ù‡Ù…Ø²Ù…Ø§Ù† Ù…Ø­ØµÙˆÙ„ {processed_count} Ø§Ø² {total_products} Ø¯Ø± ØªØ¨ {i+1}")
                        
                        # Ø§ÛŒØ¬Ø§Ø¯ Ùˆ Ø´Ø±ÙˆØ¹ thread
                        thread = threading.Thread(
                            target=self.process_single_product_thread,
                            args=(product_url, tab_handle, i+1, results_queue)
                        )
                        thread.daemon = True
                        thread.start()
                        threads.append(thread)
                
                # Ø§Ù†ØªØ¸Ø§Ø± Ø¨Ø±Ø§ÛŒ ØªÚ©Ù…ÛŒÙ„ Ù‡Ù…Ù‡ thread Ù‡Ø§
                for thread in threads:
                    thread.join()
                
                # Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ù†ØªØ§ÛŒØ¬ Ø§Ø² ØµÙ
                batch_results = []
                while not results_queue.empty():
                    result = results_queue.get()
                    if result['success'] and result['product_data']:
                        batch_results.append(result['product_data'])
                        self.scraped_products.append(result['product_data'])
                        self.logger.info(f"âœ… Thread {result['thread_id']}: Ø¯Ø§Ø¯Ù‡ Ù…Ø­ØµÙˆÙ„ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯")
                
                print(f"ğŸ‰ batch ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯ - {len(batch_results)} Ù…Ø­ØµÙˆÙ„ Ù…ÙˆÙÙ‚ Ø§Ø² {len(current_batch)}")
                
                # ØªØ§Ø®ÛŒØ± Ø¨ÛŒÙ† batch Ù‡Ø§ Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø¨Ù„Ø§Ú© Ø´Ø¯Ù†
                if batch_end < total_products:
                    batch_delay = random.uniform(3, 5)
                    self.logger.info(f"â±ï¸ Ø§Ù†ØªØ¸Ø§Ø± {batch_delay:.1f} Ø«Ø§Ù†ÛŒÙ‡ Ù‚Ø¨Ù„ Ø§Ø² batch Ø¨Ø¹Ø¯ÛŒ...")
                    time.sleep(batch_delay)
            
            # Ø¨Ø§Ø²Ú¯Ø´Øª Ø¨Ù‡ ØªØ¨ Ø§ØµÙ„ÛŒ
            self.driver.switch_to.window(tab_handles[0])
            self.logger.info("âœ… Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù‡Ù…Ø²Ù…Ø§Ù† ØªÙ…Ø§Ù… Ù…Ø­ØµÙˆÙ„Ø§Øª ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯")
            
        except Exception as e:
            self.logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù‡Ù…Ø²Ù…Ø§Ù† Ù…Ø­ØµÙˆÙ„Ø§Øª: {e}")

    def run_parallel(self):
        """
        Ø§Ø¬Ø±Ø§ÛŒ Ø§ØµÙ„ÛŒ Ø±Ø¨Ø§Øª Ø¨Ø§ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ÙˆØ§Ø²ÛŒ - Ù†Ø³Ø®Ù‡ Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ÙØªÙ‡
        """
        try:
            print("ğŸš€ Ø´Ø±ÙˆØ¹ Ø§Ø¬Ø±Ø§ÛŒ Ø±Ø¨Ø§Øª Ø§Ø³Ú©Ø±Ù¾ÛŒÙ†Ú¯ Ù…ÙˆØ§Ø²ÛŒ...")
            self.setup_driver()
            product_links = self.extract_product_links()
            
            if not product_links:
                self.logger.error("âŒ Ù‡ÛŒÚ† Ù„ÛŒÙ†Ú© Ù…Ø­ØµÙˆÙ„ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯")
                return
                
            # Ù†Ù…Ø§ÛŒØ´ ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ù…Ø­ØµÙˆÙ„Ø§Øª
            total_products_count = len(product_links)
            print(f"\nğŸ“Š ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ù…Ø­ØµÙˆÙ„Ø§Øª ÛŒØ§ÙØª Ø´Ø¯Ù‡: {total_products_count}")
            print(f"ğŸ¯ Ø´Ø±ÙˆØ¹ ÙØ±Ø¢ÛŒÙ†Ø¯ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø·Ù„Ø§Ø¹Ø§Øª...")
            print("=" * 60)
            
            # Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ ØªØ¨â€ŒÙ‡Ø§ÛŒ Ù…ØªØ¹Ø¯Ø¯
            num_tabs = 2
            tab_handles = self.setup_multiple_tabs(num_tabs)
            processed_count = 0
            
            self.logger.info(f"ğŸš€ Ø´Ø±ÙˆØ¹ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù‡Ù…Ø²Ù…Ø§Ù† {total_products_count} Ù…Ø­ØµÙˆÙ„ Ø¨Ø§ {len(tab_handles)} ØªØ¨")
            
            # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¨Ù‡ ØµÙˆØ±Øª batch Ù‡Ø§ÛŒ Ù…ÙˆØ§Ø²ÛŒ
            for batch_start in range(0, total_products_count, num_tabs):
                batch_end = min(batch_start + num_tabs, total_products_count)
                current_batch = product_links[batch_start:batch_end]
                
                batch_number = batch_start // num_tabs + 1
                total_batches = (total_products_count + num_tabs - 1) // num_tabs
                
                print(f"\nğŸ“¦ Batch {batch_number} Ø§Ø² {total_batches}")
                print(f"ğŸ”„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù‡Ù…Ø²Ù…Ø§Ù† Ù…Ø­ØµÙˆÙ„Ø§Øª {batch_start + 1} ØªØ§ {batch_end} Ø§Ø² {total_products_count}")
                
                # Ø§ÛŒØ¬Ø§Ø¯ ØµÙ Ø¨Ø±Ø§ÛŒ Ù†ØªØ§ÛŒØ¬
                results_queue = queue.Queue()
                threads = []
                
                # Ø´Ø±ÙˆØ¹ thread Ù‡Ø§ Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù‡Ù…Ø²Ù…Ø§Ù†
                for i, product_url in enumerate(current_batch):
                    if i < len(tab_handles):
                        tab_handle = tab_handles[i]
                        current_product_number = batch_start + i + 1
                        
                        print(f"   ğŸ”„ ØªØ¨ {i+1}: Ø´Ø±ÙˆØ¹ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø­ØµÙˆÙ„ {current_product_number} Ø§Ø² {total_products_count}")
                        
                            # Ø§ÛŒØ¬Ø§Ø¯ Ùˆ Ø´Ø±ÙˆØ¹ thread
                        thread = threading.Thread(
                                target=self.process_single_product_thread,
                                args=(product_url, tab_handle, current_product_number, results_queue)
                        )
                        thread.daemon = True
                        thread.start()
                        threads.append(thread)
                
                # Ø§Ù†ØªØ¸Ø§Ø± Ø¨Ø±Ø§ÛŒ ØªÚ©Ù…ÛŒÙ„ Ù‡Ù…Ù‡ thread Ù‡Ø§
                for thread in threads:
                    thread.join()
                
                # Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ù†ØªØ§ÛŒØ¬ Ø§Ø² ØµÙ
                batch_results = []
                successful_in_batch = 0
                
                while not results_queue.empty():
                    result = results_queue.get()
                    if result['success'] and result['product_data']:
                        batch_results.append(result['product_data'])
                        self.scraped_products.append(result['product_data'])
                        successful_in_batch += 1
                        processed_count += 1
                        print(f"   âœ… Ù…Ø­ØµÙˆÙ„ {result['thread_id']} : Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÙˆÙÙ‚ ({processed_count} Ø§Ø² {total_products_count})")
                    else:
                        processed_count += 1
                        print(f"   âŒ Ù…Ø­ØµÙˆÙ„ {result['thread_id']} : Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†Ø§Ù…ÙˆÙÙ‚ ({processed_count} Ø§Ø² {total_products_count})")
                
                # Ù†Ù…Ø§ÛŒØ´ Ø¢Ù…Ø§Ø± batch
                failed_in_batch = len(current_batch) - successful_in_batch
                completion_percentage = (processed_count / total_products_count) * 100
                
                print(f"ğŸ‰ Batch {batch_number} ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯:")
                print(f"   âœ… Ù…ÙˆÙÙ‚: {successful_in_batch}")
                print(f"   âŒ Ù†Ø§Ù…ÙˆÙÙ‚: {failed_in_batch}")
                print(f"   ğŸ“ˆ Ù¾ÛŒØ´Ø±ÙØª Ú©Ù„ÛŒ: {completion_percentage:.1f}% ({processed_count}/{total_products_count})")
                
                # ØªØ§Ø®ÛŒØ± Ø¨ÛŒÙ† batch Ù‡Ø§
                if batch_end < total_products_count:
                    batch_delay = random.uniform(3, 5)
                    remaining_products = total_products_count - processed_count
                    print(f"â±ï¸ Ø§Ù†ØªØ¸Ø§Ø± {batch_delay:.1f} Ø«Ø§Ù†ÛŒÙ‡ Ù‚Ø¨Ù„ Ø§Ø² batch Ø¨Ø¹Ø¯ÛŒ ({remaining_products} Ù…Ø­ØµÙˆÙ„ Ø¨Ø§Ù‚ÛŒâ€ŒÙ…Ø§Ù†Ø¯Ù‡)...")
                    time.sleep(batch_delay)
            
            # Ù†Ù…Ø§ÛŒØ´ Ø¢Ù…Ø§Ø± Ù†Ù‡Ø§ÛŒÛŒ
            successful_total = len([p for p in self.scraped_products if p.get('title')])
            failed_total = total_products_count - successful_total
            
            print(f"\nğŸ ÙØ±Ø¢ÛŒÙ†Ø¯ Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯!")
            print(f"ğŸ“Š Ø¢Ù…Ø§Ø± Ù†Ù‡Ø§ÛŒÛŒ:")
            print(f"   ğŸ”¢ ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ù…Ø­ØµÙˆÙ„Ø§Øª: {total_products_count}")
            print(f"   âœ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÙˆÙÙ‚: {successful_total}")
            print(f"   âŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†Ø§Ù…ÙˆÙÙ‚: {failed_total}")
            print(f"   ğŸ“ˆ Ø¯Ø±ØµØ¯ Ù…ÙˆÙÙ‚ÛŒØª: {(successful_total/total_products_count)*100:.1f}%")
            
            # Ø¨Ø§Ø²Ú¯Ø´Øª Ø¨Ù‡ ØªØ¨ Ø§ØµÙ„ÛŒ
            self.driver.switch_to.window(tab_handles[0])
            
            # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
            self.save_data()
            print("\nğŸ‰ Ø±Ø¨Ø§Øª Ù…ÙˆØ§Ø²ÛŒ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ú©Ø§Ø± Ø®ÙˆØ¯ Ø±Ø§ ØªÙ…Ø§Ù… Ú©Ø±Ø¯!")
            
        except KeyboardInterrupt:
            self.logger.info("â¹ï¸ Ø±Ø¨Ø§Øª ØªÙˆØ³Ø· Ú©Ø§Ø±Ø¨Ø± Ù…ØªÙˆÙ‚Ù Ø´Ø¯")
            print(f"\nâ¹ï¸ Ø±Ø¨Ø§Øª Ù…ØªÙˆÙ‚Ù Ø´Ø¯ - ØªØ§ Ø§ÛŒÙ† Ù„Ø­Ø¸Ù‡ {len(self.scraped_products)} Ù…Ø­ØµÙˆÙ„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯Ù‡ Ø¨ÙˆØ¯")
        except Exception as e:
            self.logger.error(f"âŒ Ø®Ø·Ø§ÛŒ Ú©Ù„ÛŒ Ø¯Ø± Ø§Ø¬Ø±Ø§ÛŒ Ø±Ø¨Ø§Øª Ù…ÙˆØ§Ø²ÛŒ: {e}")
        finally:
            self.cleanup()


def main():
    """
    ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡
    """
    print("=" * 60)
    print("ğŸš€ Ø±Ø¨Ø§Øª Ø§Ø³Ú©Ø±Ù¾ÛŒÙ†Ú¯ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ´Ø¯Ù‡")
    print("=" * 60)
    
    config_file = "config.json"
    if not os.path.exists(config_file):
        print(f"âŒ ÙØ§ÛŒÙ„ Ú©Ø§Ù†ÙÛŒÚ¯ ÛŒØ§ÙØª Ù†Ø´Ø¯: {config_file}")
        print("Ù„Ø·ÙØ§Ù‹ Ø§Ø¨ØªØ¯Ø§ ÙØ§ÛŒÙ„ config.json Ø±Ø§ Ø§ÛŒØ¬Ø§Ø¯ Ú©Ù†ÛŒØ¯")
        return
        
    scraper = ProductScraper(config_file)
    scraper.run_parallel()

if __name__ == "__main__":
    main()